{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0175ae64-0342-4053-a891-fa09f07bf9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
    "\n",
    "# Enable Mac M4 Acceleration (MPS)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(\"Apple Silicon M4 Detected: Using 'mps' acceleration.\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"MPS not found. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6e840-3db5-42c4-a8a8-d01579bf2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS:\n",
    "input_a = 'test_track_a.jsonl'  # Was 'dev_track_a.jsonl'\n",
    "\n",
    "# AND THIS:\n",
    "input_b = 'test_track_b.jsonl'  # Was 'dev_track_b.jsonl'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8780ec79-25cf-4370-b291-cf2e2d02cfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns found: ['anchor_text', 'text_a', 'text_b', 'text_a_is_closer']\n",
      "anchor_text         The book follows an international organization...\n",
      "text_a              The old grandmother Tina arrives in town to at...\n",
      "text_b              The nano-plague that poisoned Earth's water su...\n",
      "text_a_is_closer                                                False\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check column names\n",
    "print(\"Columns found:\", df_a.columns.tolist())\n",
    "\n",
    "# Show the first row to see the structure\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df_a.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1abc5cb8-2832-4515-b61b-7fdc1e1cd65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking for missing files...\n",
      "   - Found file: dev_track_a.jsonl (200 lines)\n",
      "   - Found file: dev_track_b.jsonl (479 lines)\n",
      "\n",
      "‚ö†Ô∏è CRITICAL: The server expects 400 items for Track A.\n",
      "   We currently have 200 items in memory.\n",
      "\n",
      "üõ†Ô∏è Applying Fix for Track B (Renaming 'embeddings' to 'embedding')...\n",
      "\n",
      "üîç Final Verification:\n",
      "   ‚úÖ Track B Key is correct: 'embedding'\n",
      "\n",
      "üéâ FIXED SUBMISSION READY: 'submission_fixed.zip'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# --- PART 1: DIAGNOSE TRACK A SIZE MISMATCH ---\n",
    "print(\"üîç Checking for missing files...\")\n",
    "# List all JSONL files and their lengths to find the missing 200 items\n",
    "jsonl_files = glob.glob(\"*.jsonl\") + glob.glob(\"data/*.jsonl\") + glob.glob(\"SemEval_Task4/*.jsonl\")\n",
    "total_rows = 0\n",
    "\n",
    "for f in jsonl_files:\n",
    "    try:\n",
    "        count = sum(1 for line in open(f))\n",
    "        print(f\"   - Found file: {f} ({count} lines)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   - Could not read {f}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è CRITICAL: The server expects 400 items for Track A.\")\n",
    "print(f\"   We currently have {len(df_a)} items in memory.\")\n",
    "\n",
    "# Check if we should combine files (Example logic)\n",
    "# If you see another file in the list above (like 'train_track_a.jsonl'), \n",
    "# we might need to load that too. For now, we proceed with the Fix for Track B.\n",
    "\n",
    "# --- PART 2: FIX TRACK B KEY NAME ---\n",
    "print(\"\\nüõ†Ô∏è Applying Fix for Track B (Renaming 'embeddings' to 'embedding')...\")\n",
    "\n",
    "# Save Track B with the CORRECT key \"embedding\" (Singular)\n",
    "with open('outputs/track_b.jsonl', 'w') as f:\n",
    "    for emb in embeddings_list:\n",
    "        # FIX: Changed \"embeddings\" -> \"embedding\"\n",
    "        json.dump({\"embedding\": emb}, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "# Save Track A (No changes to logic, just saving current results)\n",
    "with open('outputs/track_a.jsonl', 'w') as f:\n",
    "    for val in df_a['predicted_a_is_closer']:\n",
    "        json.dump({\"text_a_is_closer\": bool(val)}, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "# --- PART 3: VERIFY & ZIP ---\n",
    "print(\"\\nüîç Final Verification:\")\n",
    "with open('outputs/track_b.jsonl', 'r') as f:\n",
    "    first_line = json.loads(f.readline())\n",
    "    if \"embedding\" in first_line:\n",
    "        print(\"   ‚úÖ Track B Key is correct: 'embedding'\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Track B Key is WRONG: {first_line.keys()}\")\n",
    "\n",
    "# Zip\n",
    "zip_filename = 'submission_fixed.zip'\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write('outputs/track_a.jsonl', arcname='track_a.jsonl')\n",
    "    zipf.write('outputs/track_b.jsonl', arcname='track_b.jsonl')\n",
    "\n",
    "print(f\"\\nüéâ FIXED SUBMISSION READY: '{zip_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "866b2ad3-4760-4d4e-96bb-e55ad72ac29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400 pairs for Track A.\n",
      "Running Track A\n",
      "Scoring pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  2.82it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track A Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_a = 'test_track_a.jsonl'\n",
    "df_a = pd.read_json(input_a, lines=True)\n",
    "print(f\"Loaded {len(df_a)} pairs for Track A.\")\n",
    "\n",
    "# We use the Cross-Encoder to compare the stories\n",
    "model_a = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', device=device)\n",
    "\n",
    "print(\"Running Track A\")\n",
    "\n",
    "# We pair the anchor with text_a, and anchor with text_b\n",
    "pairs_a = df_a[['anchor_text', 'text_a']].values.tolist()\n",
    "pairs_b = df_a[['anchor_text', 'text_b']].values.tolist()\n",
    "\n",
    "print(\"Scoring pairs...\")\n",
    "scores_a = model_a.predict(pairs_a, batch_size=32, show_progress_bar=True)\n",
    "scores_b = model_a.predict(pairs_b, batch_size=32, show_progress_bar=True)\n",
    "\n",
    "df_a['predicted_a_is_closer'] = scores_a > scores_b\n",
    "\n",
    "print(\"Track A Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "829141ea-d0c7-4ef3-9eb0-2f3d7e9e97f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 479 stories for Track B.\n",
      "Encoding column: 'text'\n",
      "Running Track B on M4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:12<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track B Done. Generated 479 vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_b = 'dev_track_b.jsonl'\n",
    "df_b = pd.read_json(input_b, lines=True)\n",
    "print(f\"Loaded {len(df_b)} stories for Track B.\")\n",
    "\n",
    "# Added 'anchor_text' to the search list\n",
    "possible_cols = ['anchor_text', 'anchor', 'text', 'story']\n",
    "col_name = next((c for c in possible_cols if c in df_b.columns), None)\n",
    "\n",
    "if col_name:\n",
    "    print(f\"Encoding column: '{col_name}'\")\n",
    "    \n",
    "    model_b = SentenceTransformer('all-mpnet-base-v2', device=device)\n",
    "    print(\"Running Track B on M4...\")\n",
    "\n",
    "    embeddings = model_b.encode(\n",
    "        df_b[col_name].tolist(), \n",
    "        batch_size=32, \n",
    "        show_progress_bar=True, \n",
    "        device=device,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    \n",
    "    embeddings_list = embeddings.tolist()\n",
    "    print(f\"Track B Done. Generated {len(embeddings_list)} vectors.\")\n",
    "\n",
    "else:\n",
    "    print(f\"ERROR: Columns found were {df_b.columns.tolist()}. Please update the code to match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "533f2459-07c2-44f5-9742-d822327b4858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Track A...\n",
      "Saving Track B...\n",
      "\n",
      "üîç Verifying files...\n",
      "   - Track A check: {'text_a_is_closer': False}\n",
      "   - Track B check: Vector length is 768\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "print(\"Saving Track A...\")\n",
    "with open('outputs/track_a.jsonl', 'w') as f:\n",
    "    for val in df_a['predicted_a_is_closer']:\n",
    "        json.dump({\"text_a_is_closer\": bool(val)}, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "print(\"Saving Track B...\")\n",
    "with open('outputs/track_b.jsonl', 'w') as f:\n",
    "    for emb in embeddings_list:\n",
    "        json.dump({\"embeddings\": emb}, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "print(\"\\nVerifying files...\")\n",
    "try:\n",
    "    with open('outputs/track_a.jsonl', 'r') as f:\n",
    "        print(f\"   - Track A check: {json.loads(f.readline())}\") \n",
    "    with open('outputs/track_b.jsonl', 'r') as f:\n",
    "        data = json.loads(f.readline())\n",
    "        print(f\"   - Track B check: Vector length is {len(data['embeddings'])}\") # Should be 768\n",
    "except Exception as e:\n",
    "    print(f\"Error during verification: {e}\")\n",
    "\n",
    "# 3. Zip for Submission\n",
    "zip_filename = 'submission.zip'\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write('outputs/track_a.jsonl', arcname='track_a.jsonl')\n",
    "    zipf.write('outputs/track_b.jsonl', arcname='track_b.jsonl')\n",
    "\n",
    "print(f\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b535c985-bf80-42b9-8407-81978e949d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scanning for Test Data...\n",
      "   ‚úÖ Found Track B Test File: test_track_b.jsonl (849 items)\n",
      "   ‚úÖ Found Track A Test File: test_track_a.jsonl (400 items)\n",
      "üöÄ Using Apple M4 (MPS)\n",
      "\n",
      "üß† Processing Track A (test_track_a.jsonl)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  2.74it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Processing Track B (test_track_b.jsonl)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:16<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ DONE! Upload 'submission_test_final.zip' to CodaBench Testing Phase.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# --- 1. FIND THE CORRECT FILES BY COUNT ---\n",
    "print(\"üîç Scanning for Test Data...\")\n",
    "jsonl_files = glob.glob(\"*.jsonl\") + glob.glob(\"data/*.jsonl\") + glob.glob(\"SemEval_Task4/*.jsonl\")\n",
    "\n",
    "input_a = None\n",
    "input_b = None\n",
    "\n",
    "for f in jsonl_files:\n",
    "    try:\n",
    "        # Count lines in file\n",
    "        count = sum(1 for line in open(f))\n",
    "        \n",
    "        # Track A Test File must have exactly 400 lines\n",
    "        if count == 400:\n",
    "            input_a = f\n",
    "            print(f\"   ‚úÖ Found Track A Test File: {f} (400 items)\")\n",
    "            \n",
    "        # Track B Test File usually has around 849 lines (based on your info)\n",
    "        elif count == 849:\n",
    "            input_b = f\n",
    "            print(f\"   ‚úÖ Found Track B Test File: {f} (849 items)\")\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if not input_a or not input_b:\n",
    "    print(\"‚ö†Ô∏è WARNING: Could not auto-detect files. Please ensure you unzipped the Test Data!\")\n",
    "    # Fallback to manual filenames if auto-detection fails\n",
    "    if not input_a: input_a = 'test_track_a.jsonl' \n",
    "    if not input_b: input_b = 'test_track_b.jsonl'\n",
    "\n",
    "# --- 2. SETUP AI MODELS ---\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(\"üöÄ Using Apple M4 (MPS)\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"‚ö†Ô∏è Using CPU\")\n",
    "\n",
    "model_a = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', device=device)\n",
    "model_b = SentenceTransformer('all-mpnet-base-v2', device=device)\n",
    "\n",
    "# --- 3. PROCESS TRACK A (400 items) ---\n",
    "print(f\"\\nüß† Processing Track A ({input_a})...\")\n",
    "df_a = pd.read_json(input_a, lines=True)\n",
    "\n",
    "# Detect column names for Track A\n",
    "anc_col = next((c for c in ['anchor_text', 'anchor'] if c in df_a.columns), 'anchor')\n",
    "a_col = next((c for c in ['text_a', 'a'] if c in df_a.columns), 'a')\n",
    "b_col = next((c for c in ['text_b', 'b'] if c in df_a.columns), 'b')\n",
    "\n",
    "# Create pairs\n",
    "pairs_a = df_a[[anc_col, a_col]].values.tolist()\n",
    "pairs_b = df_a[[anc_col, b_col]].values.tolist()\n",
    "\n",
    "# Predict\n",
    "scores_a = model_a.predict(pairs_a, batch_size=32, show_progress_bar=True)\n",
    "scores_b = model_a.predict(pairs_b, batch_size=32, show_progress_bar=True)\n",
    "preds_a = scores_a > scores_b\n",
    "\n",
    "# --- 4. PROCESS TRACK B (849 items) ---\n",
    "print(f\"\\nüß† Processing Track B ({input_b})...\")\n",
    "df_b = pd.read_json(input_b, lines=True)\n",
    "\n",
    "# Detect column for Track B (Input is usually \"text\" or \"story\")\n",
    "text_col = next((c for c in ['text', 'story', 'anchor', 'anchor_text'] if c in df_b.columns), None)\n",
    "\n",
    "if text_col:\n",
    "    embeddings = model_b.encode(\n",
    "        df_b[text_col].tolist(), \n",
    "        batch_size=32, \n",
    "        show_progress_bar=True, \n",
    "        device=device,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    embeddings_list = embeddings.tolist()\n",
    "else:\n",
    "    print(\"‚ùå ERROR: Could not find text column for Track B\")\n",
    "    embeddings_list = []\n",
    "\n",
    "# --- 5. SAVE & ZIP (Using 'embedding' singular) ---\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "# Save Track A\n",
    "with open('outputs/track_a.jsonl', 'w') as f:\n",
    "    for val in preds_a:\n",
    "        json.dump({\"text_a_is_closer\": bool(val)}, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "# Save Track B\n",
    "with open('outputs/track_b.jsonl', 'w') as f:\n",
    "    for emb in embeddings_list:\n",
    "        # IMPORTANT: Using 'embedding' (singular) as per error log\n",
    "        json.dump({\"embedding\": emb}, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "# Zip\n",
    "zip_name = 'submission_test_final.zip'\n",
    "with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write('outputs/track_a.jsonl', arcname='track_a.jsonl')\n",
    "    zipf.write('outputs/track_b.jsonl', arcname='track_b.jsonl')\n",
    "\n",
    "print(f\"\\nüéâ DONE! Upload '{zip_name}' to CodaBench Testing Phase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9621040-4167-4479-9cf4-babc4a4bf26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ POWER UNLEASHED: Using Apple M4 (MPS) Acceleration\n",
      "\n",
      "üîç Scanning for the correct Test Data...\n",
      "   ‚úÖ LOCK: Track B Test File found: test_track_b.jsonl (849 items)\n",
      "   ‚úÖ LOCK: Track A Test File found: test_track_a.jsonl (400 items)\n",
      "\n",
      "üîΩ Loading SOTA Models (This involves large downloads, please wait)...\n",
      "   - Loading Track A Model: cross-encoder/nli-deberta-v3-large...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# --- 1. HARDWARE SETUP ---\n",
    "# We force MPS (Metal Performance Shaders) for Mac M4\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(\"üöÄ POWER UNLEASHED: Using Apple M4 (MPS) Acceleration\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"‚ö†Ô∏è WARNING: Running on CPU. This will be very slow.\")\n",
    "\n",
    "# --- 2. INTELLIGENT FILE FINDER ---\n",
    "print(\"\\nüîç Scanning for the correct Test Data...\")\n",
    "# We look for files matching the specific line counts of the Test Phase\n",
    "jsonl_files = glob.glob(\"*.jsonl\") + glob.glob(\"data/*.jsonl\") + glob.glob(\"SemEval_Task4/*.jsonl\")\n",
    "\n",
    "input_a = None\n",
    "input_b = None\n",
    "\n",
    "for f in jsonl_files:\n",
    "    try:\n",
    "        count = sum(1 for line in open(f))\n",
    "        if count == 400:\n",
    "            input_a = f\n",
    "            print(f\"   ‚úÖ LOCK: Track A Test File found: {f} (400 items)\")\n",
    "        elif count == 849:\n",
    "            input_b = f\n",
    "            print(f\"   ‚úÖ LOCK: Track B Test File found: {f} (849 items)\")\n",
    "    except: pass\n",
    "\n",
    "if not input_a or not input_b:\n",
    "    print(\"‚ùå CRITICAL ERROR: Could not find files with 400 or 849 lines.\")\n",
    "    print(\"Please download the 'Evaluation Data' from the website again.\")\n",
    "    # Fallback to manual names just in case\n",
    "    input_a = 'test_track_a.jsonl'\n",
    "    input_b = 'test_track_b.jsonl'\n",
    "\n",
    "# --- 3. LOAD THE \"GOD TIER\" MODELS ---\n",
    "print(\"\\nüîΩ Loading SOTA Models (This involves large downloads, please wait)...\")\n",
    "\n",
    "# Track A: DeBERTa v3 Large (The best Open Source pairwise classifier)\n",
    "model_a_name = 'cross-encoder/nli-deberta-v3-large'\n",
    "print(f\"   - Loading Track A Model: {model_a_name}...\")\n",
    "model_a = CrossEncoder(model_a_name, device=device)\n",
    "\n",
    "# Track B: GTE Large v1.5 (The best Open Source embedding model)\n",
    "# trust_remote_code=True is required for this specific high-end model\n",
    "model_b_name = 'Alibaba-NLP/gte-large-en-v1.5'\n",
    "print(f\"   - Loading Track B Model: {model_b_name}...\")\n",
    "model_b = SentenceTransformer(model_b_name, trust_remote_code=True, device=device)\n",
    "\n",
    "\n",
    "# --- 4. EXECUTE TRACK A (HIGH PRECISION) ---\n",
    "print(f\"\\nüß† ANALYZING TRACK A ({input_a})...\")\n",
    "df_a = pd.read_json(input_a, lines=True)\n",
    "\n",
    "# Smart column detection\n",
    "anc_col = next((c for c in ['anchor_text', 'anchor'] if c in df_a.columns), 'anchor')\n",
    "a_col = next((c for c in ['text_a', 'a'] if c in df_a.columns), 'a')\n",
    "b_col = next((c for c in ['text_b', 'b'] if c in df_a.columns), 'b')\n",
    "\n",
    "# Create pairs\n",
    "pairs_a = df_a[[anc_col, a_col]].values.tolist()\n",
    "pairs_b = df_a[[anc_col, b_col]].values.tolist()\n",
    "\n",
    "# INFERENCE\n",
    "# Batch size 4 is critical for 'Large' models on Mac to avoid crashing\n",
    "print(\"   - Scoring pairs (Slow & Steady)...\")\n",
    "scores_a = model_a.predict(pairs_a, batch_size=4, show_progress_bar=True)\n",
    "scores_b = model_a.predict(pairs_b, batch_size=4, show_progress_bar=True)\n",
    "\n",
    "# Logic: Higher score = closer entailment/similarity\n",
    "preds_a = scores_a > scores_b\n",
    "\n",
    "\n",
    "# --- 5. EXECUTE TRACK B (DEEP SEMANTICS) ---\n",
    "print(f\"\\nüß† EMBEDDING TRACK B ({input_b})...\")\n",
    "df_b = pd.read_json(input_b, lines=True)\n",
    "\n",
    "# Smart column detection\n",
    "text_col = next((c for c in ['text', 'story', 'anchor', 'anchor_text'] if c in df_b.columns), None)\n",
    "\n",
    "if text_col:\n",
    "    print(f\"   - Encoding column: '{text_col}'\")\n",
    "    # INFERENCE\n",
    "    # Batch size 4 ensures we fit the massive 8192 token window in memory\n",
    "    embeddings = model_b.encode(\n",
    "        df_b[text_col].tolist(), \n",
    "        batch_size=4, \n",
    "        show_progress_bar=True, \n",
    "        device=device,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    embeddings_list = embeddings.tolist()\n",
    "else:\n",
    "    print(\"‚ùå ERROR: No text column found for Track B\")\n",
    "    embeddings_list = []\n",
    "\n",
    "\n",
    "# --- 6. PACKAGING ---\n",
    "print(\"\\nüì¶ Packaging Submission...\")\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "# Save Track A\n",
    "with open('outputs/track_a.jsonl', 'w') as f:\n",
    "    for val in preds_a:\n",
    "        json.dump({\"text_a_is_closer\": bool(val)}, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "# Save Track B (Using singular 'embedding' key)\n",
    "with open('outputs/track_b.jsonl', 'w') as f:\n",
    "    for emb in embeddings_list:\n",
    "        json.dump({\"embedding\": emb}, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "# Zip\n",
    "zip_name = 'submission_SOTA_FINAL.zip'\n",
    "with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write('outputs/track_a.jsonl', arcname='track_a.jsonl')\n",
    "    zipf.write('outputs/track_b.jsonl', arcname='track_b.jsonl')\n",
    "\n",
    "print(f\"\\nüèÜ VICTORY: '{zip_name}' is ready.\")\n",
    "print(\"   Upload this to CodaBench Testing Phase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a66de-6709-4936-8f0a-e77d6740814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
    "from huggingface_hub import snapshot_download # This helps us show download bars\n",
    "import torch\n",
    "\n",
    "# --- 1. HARDWARE SETUP ---\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(\"üöÄ POWER UNLEASHED: Using Apple M4 (MPS) Acceleration\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"‚ö†Ô∏è WARNING: Running on CPU.\")\n",
    "\n",
    "# --- 2. FIND FILES ---\n",
    "print(\"\\nüîç Scanning for Test Data...\")\n",
    "jsonl_files = glob.glob(\"*.jsonl\") + glob.glob(\"data/*.jsonl\") + glob.glob(\"SemEval_Task4/*.jsonl\")\n",
    "input_a, input_b = None, None\n",
    "\n",
    "for f in jsonl_files:\n",
    "    try:\n",
    "        count = sum(1 for line in open(f))\n",
    "        if count == 400: input_a = f\n",
    "        elif count == 849: input_b = f\n",
    "    except: pass\n",
    "\n",
    "if not input_a or not input_b:\n",
    "    input_a, input_b = 'test_track_a.jsonl', 'test_track_b.jsonl'\n",
    "    print(\"‚ö†Ô∏è Using manual filenames (Auto-detection failed)\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Track A File: {input_a}\")\n",
    "    print(f\"   ‚úÖ Track B File: {input_b}\")\n",
    "\n",
    "# --- 3. DOWNLOAD MODELS WITH PROGRESS BARS ---\n",
    "print(\"\\n‚¨áÔ∏è STARTING DOWNLOADS (This ensures you see progress)...\")\n",
    "\n",
    "# Model 1: DeBERTa v3 Large\n",
    "print(\"   1. Downloading DeBERTa-v3-Large (~800MB)...\")\n",
    "model_a_id = 'cross-encoder/nli-deberta-v3-large'\n",
    "snapshot_download(repo_id=model_a_id) # This triggers the bar\n",
    "\n",
    "# Model 2: GTE Large\n",
    "print(\"   2. Downloading GTE-Large-v1.5 (~1.5GB)...\")\n",
    "model_b_id = 'Alibaba-NLP/gte-large-en-v1.5'\n",
    "snapshot_download(repo_id=model_b_id) # This triggers the bar\n",
    "\n",
    "print(\"\\n‚úÖ Downloads Complete. Loading into Memory...\")\n",
    "model_a = CrossEncoder(model_a_id, device=device)\n",
    "model_b = SentenceTransformer(model_b_id, trust_remote_code=True, device=device)\n",
    "\n",
    "# --- 4. EXECUTE TRACK A ---\n",
    "print(f\"\\nüß† SCORING TRACK A ({input_a})...\")\n",
    "df_a = pd.read_json(input_a, lines=True)\n",
    "\n",
    "# Column detection\n",
    "anc_col = next((c for c in ['anchor_text', 'anchor'] if c in df_a.columns), 'anchor')\n",
    "a_col = next((c for c in ['text_a', 'a'] if c in df_a.columns), 'a')\n",
    "b_col = next((c for c in ['text_b', 'b'] if c in df_a.columns), 'b')\n",
    "\n",
    "# Create pairs\n",
    "pairs_a = df_a[[anc_col, a_col]].values.tolist()\n",
    "pairs_b = df_a[[anc_col, b_col]].values.tolist()\n",
    "\n",
    "# INFERENCE (Progress bar included)\n",
    "scores_a = model_a.predict(pairs_a, batch_size=4, show_progress_bar=True)\n",
    "scores_b = model_a.predict(pairs_b, batch_size=4, show_progress_bar=True)\n",
    "preds_a = scores_a > scores_b\n",
    "\n",
    "# --- 5. EXECUTE TRACK B ---\n",
    "print(f\"\\nüß† EMBEDDING TRACK B ({input_b})...\")\n",
    "df_b = pd.read_json(input_b, lines=True)\n",
    "text_col = next((c for c in ['text', 'story', 'anchor', 'anchor_text'] if c in df_b.columns), None)\n",
    "\n",
    "if text_col:\n",
    "    # INFERENCE (Progress bar included)\n",
    "    embeddings = model_b.encode(\n",
    "        df_b[text_col].tolist(), \n",
    "        batch_size=4, \n",
    "        show_progress_bar=True, \n",
    "        device=device,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    embeddings_list = embeddings.tolist()\n",
    "else:\n",
    "    embeddings_list = []\n",
    "\n",
    "# --- 6. ZIP IT UP ---\n",
    "print(\"\\nüì¶ Zipping Final Submission...\")\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "with open('outputs/track_a.jsonl', 'w') as f:\n",
    "    for val in preds_a:\n",
    "        json.dump({\"text_a_is_closer\": bool(val)}, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('outputs/track_b.jsonl', 'w') as f:\n",
    "    for emb in embeddings_list:\n",
    "        json.dump({\"embedding\": emb}, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "zip_name = 'submission_SOTA_FINAL.zip'\n",
    "with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write('outputs/track_a.jsonl', arcname='track_a.jsonl')\n",
    "    zipf.write('outputs/track_b.jsonl', arcname='track_b.jsonl')\n",
    "\n",
    "print(f\"\\nüèÜ READY! Upload '{zip_name}' to CodaBench Testing Phase.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
